input taken in. size is -  4250
unique_ids are -  4250
unique senses are -  63
vocab size is -  5166 found vectors for -  4961
Till ids replacement done
padding done.
wv created
different datasets prepared. sizes are -  3353 450 447
epochs -  10 max_iterations -  33
Now lets do it man
W_wemb,  (5167, 50) --, self.X_lids  (?, 75)
emb_l  (?, 75, 50)
pooled_l  (?, 1, 100, 1)
final_l is  (?, 100)
(?, 300)
score (?, 63)
Model created. Training the model.
hyperparameters 0.01 10 0.0001 100 0.7
accuracy on training in epoch,  0 is -  [0.35460782]
accuracy on training in epoch,  1 is -  [0.40083507]
accuracy on training in epoch,  2 is -  [0.47658813]
accuracy on training in epoch,  3 is -  [0.53862214]
accuracy on training in epoch,  4 is -  [0.58693707]
accuracy on training in epoch,  5 is -  [0.63405907]
accuracy on training in epoch,  6 is -  [0.67104083]
accuracy on training in epoch,  7 is -  [0.72711003]
accuracy on training in epoch,  8 is -  [0.74888158]
accuracy on training in epoch,  9 is -  [0.78556514]
